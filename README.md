# Tennis Transformer ðŸŽ¾

Privates Projekt um Tennis-Ergebnisse mit einem Transformer-Modell vorherzusagen.

## Ziel

Ziel ist es, anhand der letzten N Matches auf dem selben Untergrund den Sieger bei einem Tennis-Spiel zu predicten.

## Architektur

Transformer-Architektur wird benutzt, weil das Ziel ein Sequence-to-Label Modell ist. Die Match-Historie eines Spielers wird als Sequenz verarbeitet, um relevante Muster zu erkennen.

## Projektstruktur

```
tennis_transformer/
â”œâ”€â”€ data/                    # Gespeicherte Daten
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py       # ATP-Daten von GitHub laden
â”‚   â”œâ”€â”€ preprocessing.py     # Features & Match-Historie erstellen
â”‚   â”œâ”€â”€ attention.py         # Self-Attention (from scratch)
â”‚   â”œâ”€â”€ transformer.py       # Transformer-Block
â”‚   â”œâ”€â”€ model.py             # Gesamtarchitektur
â”‚   â”œâ”€â”€ dataset.py           # PyTorch Dataset
â”‚   â””â”€â”€ train.py             # Training Loop
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Installation

```bash
git clone https://github.com/DanielD0304/tennis_transformer.git
cd tennis_transformer
pip install -r requirements.txt
```

## Verwendung

```bash
# Daten laden und vorbereiten
python src/data_loader.py

# Modell trainieren
python main.py
```

## Datenquelle

ATP Match-Daten von [Jeff Sackmann's Tennis ATP Repository](https://github.com/JeffSackmann/tennis_atp) (2020-2024).

## Requirements

- Python 3.10+
- PyTorch
- pandas
- numpy
- scikit-learn
- matplotlib