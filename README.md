# Tennis Transformer ðŸŽ¾

Privates Projekt um Tennis-Ergebnisse mit einem Transformer-Modell vorherzusagen.

## Ziel

Ziel ist es, anhand der letzten N Matches auf dem selben Untergrund den Sieger bei einem Tennis-Spiel zu predicten.

## Architektur

Transformer-Architektur wird benutzt, weil das Ziel ein Sequence-to-Label Modell ist. Die Match-Historie eines Spielers wird als Sequenz verarbeitet, um relevante Muster zu erkennen.

## Projektstruktur

```
tennis_transformer/
â”œâ”€â”€ data/                    # Gespeicherte Daten
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py       # ATP-Daten von GitHub laden
â”‚   â”œâ”€â”€ preprocessing.py     # Features & Match-Historie erstellen
â”‚   â”œâ”€â”€ attention.py         # Self-Attention (from scratch)
â”‚   â”œâ”€â”€ transformer.py       # Transformer-Block
â”‚   â”œâ”€â”€ model.py             # Gesamtarchitektur
â”‚   â”œâ”€â”€ dataset.py           # PyTorch Dataset
â”‚   â””â”€â”€ train.py             # Training Loop
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Installation

```bash
git clone https://github.com/DanielD0304/tennis_transformer.git
cd tennis_transformer
pip install -r requirements.txt
```

## Verwendung

```bash
# Daten laden und vorbereiten
python src/data_loader.py

# Modell trainieren
python main.py
```

## Datenquelle

ATP Match-Daten von [Jeff Sackmann's Tennis ATP Repository](https://github.com/JeffSackmann/tennis_atp) (2020-2024).


## Lernkurve & Herausforderungen

Dieses Projekt entstand als Lern- und Portfolio-Projekt. Im Verlauf gab es zahlreiche Herausforderungen und Verbesserungen:

- **NaN/Fehlende Werte:** UrsprÃ¼nglich fÃ¼hrten fehlende oder ungÃ¼ltige Werte in den Features zu NaN-Losses. LÃ¶sung: Robustes Data Cleaning und Imputation.
- **ZeroDivisionError:** Division durch Null bei Feature-Berechnung (z.B. Aufschlagquoten) wurde durch explizite Checks verhindert.
- **Softmax & CrossEntropy:** Softmax wurde aus dem Modell entfernt, da `CrossEntropyLoss` rohe Logits erwartet.
- **Sequenzaggregation:** Statt einfachem Mittelwert wird ein [CLS]-Token als globales ReprÃ¤sentativ verwendet (wie bei BERT).
- **Ranking-Feature:** Der Rang wurde ursprÃ¼nglich als numerisches Feature genutzt, was zu AusreiÃŸern fÃ¼hrte. LÃ¶sung: log(rank+1) als Feature.
- **Segment-Embeddings:** Um dem Modell Kontext zu geben, wurden Segment-Embeddings fÃ¼r Spieler A/B und Surface/Recent eingefÃ¼hrt.
- **Match-Alter:** Das Alter jedes Matches wird als Feature (log(1+days_since_match)) Ã¼bergeben, damit das Modell aktuelle Form besser erkennt.
- **Effizientes Data Loading:** Preprocessing wird nur einmal ausgefÃ¼hrt und als .pt gespeichert, statt bei jedem Training neu zu laden.

Diese Schritte haben die Robustheit, Interpretierbarkeit und Effizienz des Projekts deutlich verbessert.